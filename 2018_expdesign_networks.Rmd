---
author: "[Nima Hejazi](https://nimahejazi.org)"
title: "Model-assisted design of experiments in the presence of network
correlated outcomes (G.W. Basse & E.M. Airoldi, 2018+)"
institution: "University of California, Berkeley"
date: "`r Sys.Date()`"
bibliography: refs.bib
output: binb::metropolis
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

# Introduction

## Interference: When people have friends

* Observational units are connected -- so far, we've been dealing with causal
  analyses _in a vacuum_.

* Sometimes, it's reasonable to assume that units do not affect one another;
  often, it's not.

* A central assumption in causal models, necessary for identification results,
  is the Stable Unit Treatment Value Assumption [@rubin1978bayesian] &
  [@rubin1980randomization].

* _Interference_ is often defined through the loosening of this assumption
  [@hudgens2008toward].

## Networks: Are you (still) on facebook too?

* In a population of causally connected units, several types of network
  structures may arise, each posing unique challenges for statistics.

* Broadly, the central statistical challenge is _"how to account for the
  presence of connections, or network data, observed pre-intervention, possibly
  with uncertainty, and often missing"_ @basse2018+model.

## Networks: Two perspectives

* Two main problem settings have been discussed in the causal inference
  literature
  1. _Network interference_: When the potential outcomes of a given unit are a
     function of its assigned treatment and that of others.
  2. _Network-correlated outcomes_: When the potential outcomes of units in a
     network are related through their baseline covariates.

* The first problem has been the subject of much attention in the literature, so
  @basse2018+model focus on resolving issues in the second setting.

# G.W. Basse and E.M. Airoldi, 2018+, _Biometrika_

## Goals and Motivation

* _The problem_: "how to assign treatment in a randomized experiment, when the
  correlation among the outcomes is informed by a network available at the
  design stage."

* Identify and estimate the causal effect of interference in the presence of
  confounding induced by correlated outcomes.

* How can information about a network be used to inform randomization strategies
  for estimating causal effects?

## Approach

* Use _model-assisted restricted randomization strategies_, leveraging a static
  network known pre-intervention.

* Restricted randomization has a long history in experimental design --
  @basse2018+model build off of this, using strategies that balance covariates
  properly.

## Approach

* Posit a working model for the potential outcomes, conditional on the network
  known pre-intervention.

* Restrict the set of allowed randomization strategies such that the estimator
  of interest achieves low MSE.

* In turn, focus on MSE suggests new notions of balance in network-based
  randomization (related to network degree statistics).

## Findings

* Proposed approach maintains design unbiasedness of the difference-in-means
  estimator, even when the working model is misspecified (i.e., robustness).

* When the working model is correct, inference is improved through higher
  precision of the estimator of interest.

## Notation

* $N$ observational units, indexed $i = 1, \ldots, N$.

* Binary treatment $Z$, where $Z_i = 1$ denotes assignment to treatment arm.

* Real-valued outcome $Y_i$, with potential outcomes $Y_i(Z_i)$:
  * $Y_i(1)$ for $Z_i = 1$ and
  * $Y_i(0)$ for $Z_i = 0$.

## Assumptions

* _Stable Unit Treatment Value Assumption_ [@rubin1974estimating] &
  [@rubin1978bayesian].
  * i.e., $Y_i(Z) = Y_i(Z_i)$
  * explicitly disallows network interference

* Finite population setting: recall that potential outcomes $Y(Z)$ are unknown
  but constant quantities, given $Z$.

## Assumptions

* _Randomized experiment_: only source of variation is the allocation of
  treatment to units (controlled by experimenter).

* Treatment allocated based on distribution on the space of all binary vectors
  of length $N$, i.e., randomization distribution [@imbens2015causal].

## Parameter of interest: ATE

* For illustration, focus on ATE as the inferential target.

* With the notation previously given, the ATE is defined as
  $$ \tau^* = \frac{1}{N}\sum_{i = 1}^N \{Y_i(1) - Y_i(0)\}$$

* Focus also on the difference-in-means estimator for the ATE:
  $$\hat{\tau}(Y \mid Z) = \frac{\sum_{i = 1}^N Z_i Y_i}{\sum_{i = 1}^N Z_i} -
    \frac{\sum_{i = 1}^N (1 - Z_i) Y_i}{\sum_{i = 1}^N (1 - Z_i)}$$

## An undirected network

* Let the network be an undirected graph $\mathcal{G}$ over $N$ units, where
   * $\mathcal{G}$ is simply an $N \times N$ binary adjacency matrix $A$, where
     all diagonal entries are unary (i.e., $A_{ii} = 1$), and
   * the neighborhood of unit $i$ be the index set
     $\mathcal{N}_i = \{j: A_{ij} = 1 \}$.

* The proposed methodology requires that a network be known at the design stage
  (pre-specified).

## A simplified model

* For illustrative purposes, assume the _normal-sum model_:
  \begin{align*}
    X_j & \sim_{iid} N(\mu, \sigma^2) \\
    Y_i(0) \mid X & \sim_{ind} N(\sum_{j \in \mathcal{N}_i} X_j, \gamma^2) \\
    Y_i(1) & = Y_i(0) + \tau
  \end{align*}

* Observations in the same group are taken to have originated from a Normal
  distribution with the same mean.

* "The network induces correlation among the outcomes that are assigned to
  control because the mean of each $Y_i(0)$ is given by the sum of the
  covariate values $X_j$ of units $j$ in a neighborhood of $i$"
  [@basse2018+model].

## A simplified model

* Constant treatment effect model: $\tau$ is the difference between the
  potential outcomes $\{Y_i(0), Y_i(1)\}$.

* _Intuition_: in the absence of network connections and treatment $Z_i = 0$:
  * $Y_i(0)$ is a measure of an intrinsic property of the observational unit
    (e.g., time spent on social media), as determined by covariates $X$.
  * Network connections alter the natural value $Y_i(0)$ that would occur,
    through the induced network structure.
  * The intervention $\text{do}(Z_i = 1)$ induces a causal effect $\tau$ such
    that $Y_i(1) = Y_i(0) + \tau$.

* The _normal-sum_ model is just a starting point...

## Optimal treatment allocation

* To ascertain an optimal treatment allocation strategy, need a notion of error
  to define optimality.

* @basse2018+model propose the _conditional MSE_:
  1. fix a treatment allocation vector $Z$, then
  2. for the _normal-sum model_, $\text{MSE}(\hat{\tau} \mid Z) \equiv
     \mathbb{E}\{(\hat{\tau} - \tau^*)^2 \mid Z \}$

* Now, an optimal treatment allocation $Z^* \in \mathcal{Z}$ is one that
  minimizes the conditional MSE.

## Where are the networks?

* A decomposition of the conditional MSE is informative of network statistics:
  \begin{equation*}
    \text{MSE}(\hat{\tau} \mid Z) = \mu^2 \{\delta_N(Z) \}^2 +
      \gamma^2 \omega(Z)^T \omega(Z) + \sigma^2 \omega(Z)^T A^T A \omega(Z)
  \end{equation*}

* Each of the terms in the MSE decomposition is informative
  * $\text{Bias}^2$: $\mu^2 \{\delta_N(Z) \}^2$
  * _Network-agnostic_ variance component: $\gamma^2 \omega(Z)^T \omega(Z)$
  * _Network-aware_ variance component: $\sigma^2 \omega(Z)^T A^T A \omega(Z)$

* Model-assisted restriction randomization strategies seek to minimize the
  conditional MSE, but tradeoffs occur.

## Bias

* The bias term admits the decomposition
  \begin{equation*}
    \mu \cdot \delta_{\mathcal{N}} = \mu \cdot \left( \frac{1}{N_1}
    \sum_{(i:Z_i = 1)} \lvert \mathcal{N}_i \rvert - \frac{1}{N_0}
    \sum_{(i:Z_i = 0)} \lvert \mathcal{N}_i \rvert \right)
  \end{equation*}

* The bias is proportional to the _average degree_ of each of the experimental
  arms (treatment and control groups).

* This is the difference in the average neighborhood sizes of the treated and
  untreated units -- i.e., balance!

* Desirable treatment allocation vectors ($Z \in \mathcal{Z}^b$) will minimize
  this difference in neighborhood sizes.

## Network-agnostic variance term

* The first part of the variance term may be decomposed
  \begin{equation*}
    \gamma^2 \omega^T \omega = \gamma^2 \left(\frac{1}{N_1} + \frac{1}{N_0}
    \right)
  \end{equation*}

* Similar to bias term, minimized when $N_1 = N_0$.

* Thus, this term penalizes a difference in the size of treatment and control
  units, and is satisfied through _balance_.

* This is similar to prior work in balanced randomizations outside of the
  context of network-correlated outcomes.

## Network-aware variance term

* The second part of the variance term may be written
  \begin{align*}
    \sigma^2 \cdot \omega^T A^T A \omega =& \frac{\sigma^2}{N_1^2} \cdot
      \sum_{i,j: Z_i = Z_j = 1} \lvert \mathcal{N}_i \cap \mathcal{N}_j
      \rvert \\
    +& \frac{\sigma^2}{N_0^2} \cdot \sum_{i,j: Z_i = Z_j = 0} \lvert
      \mathcal{N}_i \cap \mathcal{N}_j \rvert \\
    -& \frac{2\sigma^2}{N_1 \cdot N_0} \cdot \sum_{i,j: Z_i = 1 \text{and}
      Z_j = 0} \lvert \mathcal{N}_i \cap \mathcal{N}_j \rvert
  \end{align*}

* Minimize contribution of this term to the MSE by
  1. assigning units with shared neighbors to different groups, and
  2. avoiding assigning treatment or control to clusters of densely connected
     units.

## Classical randomization

* __Q:__ What's a randomization strategy?

* __A:__ Probability distributions on the set of binary vectors $\mathcal{Z}$

* Let $Z_i \sim Bern(p)$ for $p \in (0,1)$. A _Bernoulli randomization
  strategy_ is $Z = (Z_1, \ldots, Z_n) \in \mathcal{Z}$.

## Classical randomization

* _Completely randomized strategy_: restrict to $Z \in \mathcal{Z}$ such that
  $\sum_{i - 1}^n Z_i = N_1$, where
  * $N_1$ is the size of the treatment group and $N_0$ is the size of the
    control group, so $N_0 + N_1 = N$
  * _Balanced_ if $N_0 = N_1 = \frac{1}{2} \cdot N$

* Such randomization strategies restrict to a set of desirable treatment
  allocation vectors (e.g., eliminating or minimizing covariate imbalance).

## Restricted randomization

* __Q:__ What's a restricted randomization strategy?

* __A:__ Probability distributions on the set of binary vectors $\mathcal{Z}$
     implied by discarding allocation vectors $Z \in \mathcal{Z}$ according to
     a user-defined set of rules.

* To proceed, let $\mathcal{Z} \equiv \{0, 1\}^N$, the set of all possible
  treatment allocation vectors on $N$ units

## Restricted randomization

* @basse2018+model propose __4__ model-based trestricted randomization
  strategies:
  1. balanced restricted randomization strategies
  2. unbiased restricted randomization strategies
  3. optimal restricted randomization strategies
  4. unconstrained/optimal restricted randomization strategies

## $\mathcal{Z}^b$: balanced restricted randomization

* Such a strategy restricts to treatment allocation vectors in
  $$\mathcal{Z}^b \equiv \{Z \in \mathcal{Z}: N_1 - N_0 = 0\}$$

* Aim to minimize the contribution of the total variance to the conditional MSE.

* Defines _balanced restricted randomization design_: $Z \in \mathcal{Z}^b$

## $\mathcal{Z}^u$: unbiased restricted randomization

* Such a strategy restricts to treatment allocation vectors in
  $$\mathcal{Z}^u \equiv \left\{Z \in \mathcal{Z}:
    \frac{1}{N_1}\sum_{i: Z_i = 1} \lvert \mathcal{N}_i \rvert -
    \frac{1}{N_0}\sum_{i: Z_i = 0} \lvert \mathcal{N}_i \rvert = 0 \right\}$$

* Aim to minimize the contribution of the bias term to the conditional MSE.

* Defines _balanced/unbiased restricted randomization design_:
  $Z \in \mathcal{Z}^b \cap \mathcal{Z}^u$

## $\mathcal{Z}^o$: optimal restricted randomization

* Such a strategy restricts to treatment allocation vectors in
  $$\mathcal{Z}^o \equiv \{Z \in \mathcal{Z}: \text{MSE}(\hat{\tau} \mid Z)
    \leq q_{\alpha}^{\text{MSE}}\},$$
    where $q_{\alpha}^{\text{MSE}}$ is the $\alpha^{\text{th}}$-quantile of the
    distribution of the conditional MSE.

* Defines _balanced/unbiased/optimal restricted randomization design_:
  $Z \in \mathcal{Z}^b \cap \mathcal{Z}^u \cap \mathcal{Z}^o$
  * n.b., $\mathcal{Z}^b \cap \mathcal{Z}^u \cap \mathcal{Z}^o$ contains at
    least two elements $Z$ if $\mathcal{Z}^b \cap \mathcal{Z}^u \neq \emptyset$
    [@basse2018+model].

## $\mathcal{Z}^o$: optimal restricted randomization

* Control the conditional MSE through three effects:
  1. Minimize average number of shared neighbors among pairs of treated units;
  2. minimize average number of shared neighbors among pairs of untreated units;
     and
  3. maximize average number of shared neighbors among pairs of units, one of
     which is treated and the other untreated.

## $\mathcal{Z}^{\text{min}}$: unconstrained/optimal restricted randomization

* Such a strategy restricts to treatment allocation vectors in
  $$\mathcal{Z}^{\text{min}} \equiv \{Z \in \mathcal{Z}: \text{argmin}
  \text{MSE}(\hat{\tau} \mid Z) \}$$

* Trades off small increases in bias for significant reductions in variance.

* @basse2018+model do _not_ focus on this -- similarly, we'll restrict our
  attention to $\mathcal{Z}^b$, $\mathcal{Z}^u$, and $\mathcal{Z}^o$.

## Model-based optimal treatment allocation strategies

* _Idea_: use an estimator of the ATE implied by the model, then select a set of
  treatment allocation strategies based on this new estimator.
  * i.e., abandon the difference-in-means estimator

* The _optimal maximum likelihood design_ is defined as
  \begin{equation*}
    \mathcal{Z}^{\text{min}} \equiv \{Z \in \mathcal{Z}: \text{argmin}
    MSE(\hat{\tau}_{\text{MLE}} \mid Z) \}
  \end{equation*}

* Now, the strategy is married to the chosen model (e.g., normal-sum).
  * If we're clever about how we restrict our randomizations, we can still
    maintain unbiasedness (i.e.,
    $Z \in \mathcal{Z}^b \cap \mathcal{Z}^{\text{min}}$).

## Restricted randomization and re-randomization

* What was all this about _re-randomization_ again? Rejection sampling!
  (Let's let the computer do the work for us.)

* To use re-randomization for restricted randomization designs, based on whether
  certain criteria are satisfied
  \begin{align*}
    \phi^b(Z) =& \mathbb{I} \{ \sum_i^N Z_i = \sum_i^N (1 - Z_i) \} \\
    \phi^u(Z) =& \mathbb{I} \{ \mu \cdot \delta_{\mathcal{N}}(Z) = 0 \} \\
    \phi^o(Z) =& \mathbb{I} \{ \text{MSE}(\hat{\tau} \mid Z) \leq
      q_{\alpha}^{\text{MSE}} \}
  \end{align*}

* Draw treatment allocation vector $Z$ from original design, accept if
  $\phi(Z) = 1$ or discard if $\phi(Z) = 0$.

## Issues in inference

* Neymanian intervals -- restricted randomization makes these challenging as
  asymptotic theory incompatible with networks:
  1. number of covariates must be fixed, but this applies to neighbors in a
      network setting, and
  2. constraints must be a function of difference in group means and
      variance-covariance of that vector (proven not to hold).

* Bootstrap intervals? Difficult to implement due to potential complexities in
  correlation structure.

* What's left? Fisher intervals!

## Fisher intervals and inference

* Obtained by inverting a sequence of Fisher exact tests.

* Accomplished through re-randomization, where the proposed restricted
  randomization distributions are treated as the permutation distributions.

* Under balance (i.e., $Z \in \mathcal{Z}^b$), the sharp null hypothesis
  \begin{equation*}
    H_{\tau^*}: Y_i(1) = Y_i(0) + \tau^* \forall i,
  \end{equation*}
  may be inverted to generate a confidence interval wrt a sequence of $\tau^*$.
  * See B.1 in the appendix of @basse2018+model for details on the construction.

## Main result

* _Design unbiasedness_: An estimator $\hat{\tau}$ is unbiased wrt a
  distribution on $\mathcal{Z}$ if $\mathbb{E}_{\mathcal{Z}}(\hat{\tau} - \tau)
  = 0$

* The difference-in-means estimator $\hat{\tau}$ is an unbiased estimator of the
  ATE wrt
  1. uniform distribution on $\mathcal{Z}^b$, defining the _balanced_ design;
  2. uniform distribution on $\mathcal{Z}^b \cap \mathcal{Z}^u$, defining the
     _balanced/unbiased_ design;
  3. uniform distribution on $\mathcal{Z}^b \cap \mathcal{Z}^o$, defining the
     _balanced/optimal_ design; and
  4. uniform distribution on $\mathcal{Z}^b \cap \mathcal{Z}^u \cap
     \mathcal{Z}^o$, defining the _balanced/unbiased/optimal_ design.

## Main result

* As a consequence of design unbiasedness (as well as of the increasingly nested
  supports), variance of $\hat{\tau}$ may be compared across designs:
  $$\mathbb{E}\{\text{Var}_{\mathcal{Z}^b \cap \mathcal{Z}^o} (\hat{\tau} \mid
    Y) \} \leq \mathbb{E}\{\text{Var}_{\mathcal{Z}^b} (\hat{\tau} \mid Y) \}$$

* Similar inequalities exist for any pair of nested designs as long as
  $\mathcal{Z}^b$ is included in the support of designs.

* The arguments rely on _symmetry_ provided by the inclusion of $\mathcal{Z}^b$
  -- in fact, we have the following Lemma: _For $Z \in \mathcal{Z}^b$, we have
  $\hat{\tau}(1 - Z) = 2\tau - \hat{\tau}(Z)$_.

## Towards general network models

* The _normal-sum model_ we discussed is just a simple case of a much broader
  family of models
  \begin{equation*}
    Y_i(0) \mid X \sim^{ind} N(g[\{X_j\}_{j \in \mathcal{N}_i}], \gamma^2)
  \end{equation*}

* Need a few regularity conditions on $g$ to ensure that the quantity
  $\mathbb{E}(g[\{X_j\}_{j \in \mathcal{N}_i}] \mid \{X_j\}_{j \in
  \mathcal{S}})$ is well behaved for any subset of nodes $\mathcal{S} \subset
  \mathcal{N}_i$.
  * Positivity
  * Symmetry
  * Monotonicity

## Examples of general network models

* ...

* ...

* ...

## Lessons for _good designs_

* From this extended discourse on good designs, a few new rules come to light.

* Let's ask -- so, what exactly should a _good design_ do?
  1. Decrease number of shared neighbors in treatment groups.
  2. Increase number of shared units between treatment groups.
  3. Balance the size of the groups and the distribution of the sizes of
     neighborhoods.

# Alright...I've talked enough

## References

